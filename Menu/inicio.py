import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objs as go
from sklearn.cluster import KMeans
from sklearn.ensemble import RandomForestClassifier
from statsmodels.tsa.stattools import grangercausalitytests
from Menu.utilidades import procesar_archivos, RUTA_GUARDADO

# ----------------------------------------- Definiciones ---------------------------------
def mostrar_causalidad(dfEntrenamiento):
    st.title("üìà An√°lisis de Causalidad de Granger")

    # Preparar datos para an√°lisis de causalidad
    df_causalidad = dfEntrenamiento[['total_publicaciones', 'patents']].dropna()

    col1, col2 = st.columns(2)

    with col1:
        st.subheader("Publicaciones ‚Üí Patentes")
        resultados_pub_pat = grangercausalitytests(df_causalidad[['total_publicaciones', 'patents']], maxlag=2, verbose=False)
        mostrar_resultados_causalidad(resultados_pub_pat)

    with col2:
        st.subheader("Patentes ‚Üí Publicaciones")
        resultados_pat_pub = grangercausalitytests(df_causalidad[['patents', 'total_publicaciones']], maxlag=2, verbose=False)
        mostrar_resultados_causalidad(resultados_pat_pub)

    st.info("üîç **Nota:** Un valor p bajo (por ejemplo, < 0.05) indica una relaci√≥n causal significativa.")

def mostrar_resultados_causalidad(resultados):
    for lag, resultado in resultados.items():
        st.markdown(f"### Lag {lag}")
        data = {
            "Prueba": ["SSR F-test", "Chi2 test", "Likelihood ratio test"],
            "Estad√≠stico": [
                resultado[0]['ssr_ftest'][0],
                resultado[0]['ssr_chi2test'][0],
                resultado[0]['lrtest'][0]
            ],
            "p-valor": [
                resultado[0]['ssr_ftest'][1],
                resultado[0]['ssr_chi2test'][1],
                resultado[0]['lrtest'][1]
            ]
        }
        df_resultados = pd.DataFrame(data)

        # Resaltar valores p significativos
        def resaltar_p_valor(val):
            color = 'background-color: #ffcccc;' if val < 0.05 else ''
            return color

        st.dataframe(
            df_resultados.style.applymap(resaltar_p_valor, subset=["p-valor"]),
            use_container_width=True
        )

def realizar_clustering_y_clasificacion(dfEntrenamiento):
    st.title("üîç An√°lisis de Clustering y Clasificaci√≥n")

    # Clustering con KMeans
    X = dfEntrenamiento[['total_publicaciones', 'patents']].dropna()
    kmeans = KMeans(n_clusters=3, random_state=42).fit(X)
    # Solo asignar etiquetas a las filas sin NaN en X
    dfEntrenamiento['cluster'] = None
    dfEntrenamiento.loc[X.index, 'cluster'] = kmeans.labels_

    # Etiquetas mejoradas para los clusters
    cluster_labels = {i: f'Grupo {i+1}' for i in range(kmeans.n_clusters)}
    dfEntrenamiento['cluster_label'] = dfEntrenamiento['cluster'].map(cluster_labels)

    # Crear gr√°fico de dispersi√≥n interactivo
    fig_clusters = px.scatter(
        dfEntrenamiento.loc[X.index],
        x='total_publicaciones',
        y='patents',
        color='cluster_label',
        title="Visualizaci√≥n de Grupos (KMeans)",
        labels={
            'total_publicaciones': 'Total de Publicaciones',
            'patents': 'Total de Patentes',
            'cluster_label': 'Grupo'
        },
        color_discrete_sequence=px.colors.qualitative.Set1
    )

    # A√±adir centroides al gr√°fico
    centroids = kmeans.cluster_centers_
    for i, (x, y) in enumerate(centroids):
        fig_clusters.add_trace(go.Scatter(
            x=[x],
            y=[y],
            mode='markers+text',
            marker=dict(size=14, color='black', symbol='x', line=dict(width=2, color='white')),
            name=f'Centroide Grupo {i+1}',
            text=[f'Centroide {i+1}'],
            textposition='top center',
            showlegend=True
        ))

    # Clasificaci√≥n con Random Forest
    y = kmeans.labels_
    rf = RandomForestClassifier(random_state=42)
    rf.fit(X, y)

    # Importancia de caracter√≠sticas
    importances = rf.feature_importances_
    features = ['Total de Publicaciones', 'Total de Patentes']

    # Crear gr√°fico de barras para la importancia de caracter√≠sticas
    fig_importances = px.bar(
        x=features,
        y=importances,
        labels={'x': 'Caracter√≠sticas', 'y': 'Importancia'},
        title="Importancia de Caracter√≠sticas en Random Forest",
        color=importances,
        color_continuous_scale='Blues'
    )

    # Mostrar ambas gr√°ficas en una sola l√≠nea
    col1, col2 = st.columns(2)
    with col1:
        st.subheader("üìä Clustering con KMeans")
        st.plotly_chart(fig_clusters, use_container_width=True)
    with col2:
        st.subheader("üå≤ Clasificaci√≥n con Random Forest")
        st.plotly_chart(fig_importances, use_container_width=True)

def graficar_correlaciones(dfEntrenamiento):
    """
    Genera un gr√°fico de barras horizontal para mostrar la correlaci√≥n entre
    publicaciones y patentes por √°rea de conocimiento.
    """
    # Calcular correlaci√≥n por √°rea de conocimiento
    correlaciones = {}
    for col in [c for c in dfEntrenamiento.columns if c.startswith('√°rea_del_conocimiento_')]:
        subset = dfEntrenamiento[dfEntrenamiento[col] == True]
        
        # Validar que el subconjunto tenga suficientes datos y variaci√≥n
        if len(subset) > 1 and subset['total_publicaciones'].std() > 0 and subset['patents'].std() > 0:
            correlaciones[col] = subset['total_publicaciones'].corr(subset['patents'])
        else:
            correlaciones[col] = None  # No calcular si no hay suficientes datos o variaci√≥n

    # Ordenar las √°reas por correlaci√≥n
    correlaciones_ordenadas = sorted(correlaciones.items(), key=lambda x: x[1] if x[1] is not None else -float('inf'), reverse=True)

    # Filtrar √°reas con valores calculables
    areas = [area.replace('√°rea_del_conocimiento_', '').replace('_', ' ') for area, corr in correlaciones_ordenadas if corr is not None]
    valores = [corr for area, corr in correlaciones_ordenadas if corr is not None]

    # Crear el gr√°fico de barras horizontal con Plotly
    colores = ['green' if c > 0 else 'red' for c in valores]
    fig = go.Figure()

    fig.add_trace(go.Bar(
        x=valores,
        y=areas,
        orientation='h',
        marker=dict(color=colores),
        text=[f"{v:.2f}" for v in valores],
        textposition='auto',
        hoverinfo='x+y'
    ))

    # Configurar el dise√±o del gr√°fico
    fig.update_layout(
        title="Correlaci√≥n entre Publicaciones y Patentes por √Årea de Conocimiento",
        xaxis_title="Correlaci√≥n",
        yaxis_title="√Åreas de Conocimiento",
        xaxis=dict(showgrid=True, zeroline=True, zerolinecolor='black', zerolinewidth=1),
        yaxis=dict(showgrid=False),
        template='plotly_white',
        bargap=0.2
    )

    return fig

# ----------------------------------------- Codigo ---------------------------------
def mostrar_inicio(rutaAnalisis):
    correctos, incorrectos, archivos_incorrectos = procesar_archivos(RUTA_GUARDADO)
    dfEntrenamiento = pd.read_csv(rutaAnalisis)

    st.title("üìä Informe de Archivos Procesados")
    col1, col2, col3 = st.columns(3)
    col1.metric("Archivos correctos", correctos)
    col2.metric("Archivos con error", incorrectos)
    col3.metric("Archivos en total", correctos + incorrectos)

    if incorrectos > 0:
        st.subheader("Archivos con error:")
        for archivo in archivos_incorrectos:
            st.write(f"- {archivo}")

    # Gr√°fico de barras
    data = {
        'Categor√≠a': ['Correctos', 'Incorrectos'],
        'Cantidad': [correctos, incorrectos]
    }
    df = pd.DataFrame(data)

    fig = px.bar(df, x='Categor√≠a', y='Cantidad', color='Categor√≠a',
                 title="Archivos Procesados Correctamente vs Incorrectamente",
                 labels={'Cantidad': 'N√∫mero de Archivos'},
                 height=400)

    st.plotly_chart(fig)

    # Crear una lista para almacenar los resultados
    resultados = []

    # Iterar sobre las columnas que comienzan con '√°rea_del_conocimiento_'
    for col in [c for c in dfEntrenamiento.columns if c.startswith('√°rea_del_conocimiento_')]:
        subset = dfEntrenamiento[dfEntrenamiento[col] == True]
        resultados.append({
            "√Årea": col.replace('√°rea_del_conocimiento_', '').replace('_', ' ').capitalize(),
            "Tama√±o del subconjunto": len(subset),
            "Desviaci√≥n est√°ndar (Publicaciones)": subset['total_publicaciones'].std(),
            "Desviaci√≥n est√°ndar (Patentes)": subset['patents'].std()
        })

    # Convertir los resultados en un DataFrame
    df_resultados = pd.DataFrame(resultados)

    # Mostrar los resultados en Streamlit
    st.title("üìã Correlaci√≥n entre Publicaciones y Patentes")

    col_fig1, col_fig2 = st.columns(2)
    with col_fig1:
        fig = px.bar(
            df_resultados,
            x="√Årea",
            y=["Desviaci√≥n est√°ndar (Publicaciones)", "Desviaci√≥n est√°ndar (Patentes)"],
            title="Desviaci√≥n Est√°ndar de Publicaciones y Patentes por √Årea del Conocimiento",
            barmode="group",
            labels={"value": "Desviaci√≥n est√°ndar", "variable": "Tipo"},
            height=400
        )
        st.plotly_chart(fig, use_container_width=True)

    with col_fig2:
        fig_correlaciones = graficar_correlaciones(dfEntrenamiento)
        st.plotly_chart(fig_correlaciones, use_container_width=True)

    mostrar_causalidad(dfEntrenamiento)
    realizar_clustering_y_clasificacion(dfEntrenamiento)